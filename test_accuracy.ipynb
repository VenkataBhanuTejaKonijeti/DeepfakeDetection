{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1DQN5Z0BLA0gw6YfA61jrKD4-sLwZDhMQ",
      "authorship_tag": "ABX9TyN/n7ZPwwiChP245pe/WU4W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e4c8372464e1435c842513d9d8ef4b98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5cf47e262a4e47c0a8fdfcb824ba4e76",
              "IPY_MODEL_c2bc07873c874558ac4c0624db7e84fe",
              "IPY_MODEL_ce41db906ef44e299680d3ec0aadb87b"
            ],
            "layout": "IPY_MODEL_26c8e994bf2b4637bc72ff9dbc1c4c6d"
          }
        },
        "5cf47e262a4e47c0a8fdfcb824ba4e76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_158a10abe7674257858cf20a17ab7656",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_75c5fbd778b14539857a45a74bac1564",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "c2bc07873c874558ac4c0624db7e84fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c0d272d33534effb6afc871614c6d73",
            "max": 173153470,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a48fd8a218904e4b99575cc573fe828d",
            "value": 173153470
          }
        },
        "ce41db906ef44e299680d3ec0aadb87b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a18029b881ef490baeadc9546a6d457b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_bf5655e64d3048bcba49e9ef2fac2ee4",
            "value": "‚Äá173M/173M‚Äá[00:00&lt;00:00,‚Äá231MB/s]"
          }
        },
        "26c8e994bf2b4637bc72ff9dbc1c4c6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "158a10abe7674257858cf20a17ab7656": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75c5fbd778b14539857a45a74bac1564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c0d272d33534effb6afc871614c6d73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a48fd8a218904e4b99575cc573fe828d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a18029b881ef490baeadc9546a6d457b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf5655e64d3048bcba49e9ef2fac2ee4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VenkataBhanuTejaKonijeti/DeepfakeDetection/blob/main/test_accuracy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ttach"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BX15jaY1_iCD",
        "outputId": "588056d1-1489-4a71-8f63-a721423cff69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ttach\n",
            "  Downloading ttach-0.0.3-py3-none-any.whl.metadata (5.2 kB)\n",
            "Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\n",
            "Installing collected packages: ttach\n",
            "Successfully installed ttach-0.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JemVX_-B_p2j",
        "outputId": "241154a0-c21e-4248-af4c-b832712c3bd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import timm\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from google.colab import drive\n",
        "\n",
        "# ================================\n",
        "# 1Ô∏è‚É£ MOUNT GOOGLE DRIVE & SET PATHS\n",
        "# ================================\n",
        "drive.mount('/content/drive', force_remount=True)  # Ensure remount\n",
        "dataset_zip = \"/content/drive/MyDrive/dataset.zip\"\n",
        "extract_path = \"/content/dataset_extracted\"\n",
        "\n",
        "# ================================\n",
        "# 2Ô∏è‚É£ EXTRACT THE DATASET\n",
        "# ================================\n",
        "if not os.path.exists(extract_path):\n",
        "    with zipfile.ZipFile(dataset_zip, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "print(\"‚úÖ Dataset extracted successfully!\")\n",
        "\n",
        "# ================================\n",
        "# 3Ô∏è‚É£ ORGANIZE IMAGES INTO 'REAL' & 'FAKE' FOLDERS\n",
        "# ================================\n",
        "train_real_folder = os.path.join(extract_path, \"training_real\")\n",
        "train_fake_folder = os.path.join(extract_path, \"training_fake\")\n",
        "train_path = os.path.join(extract_path, \"train\")\n",
        "test_path = os.path.join(extract_path, \"test\")\n",
        "\n",
        "for category in [\"real\", \"fake\"]:\n",
        "    os.makedirs(os.path.join(train_path, category), exist_ok=True)\n",
        "    os.makedirs(os.path.join(test_path, category), exist_ok=True)\n",
        "\n",
        "def move_images(source_folder, dest_folder):\n",
        "    valid_extensions = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\", \".webp\"}\n",
        "    for image_name in os.listdir(source_folder):\n",
        "        if any(image_name.lower().endswith(ext) for ext in valid_extensions):\n",
        "            shutil.move(os.path.join(source_folder, image_name), os.path.join(dest_folder, image_name))\n",
        "\n",
        "move_images(train_real_folder, os.path.join(train_path, \"real\"))\n",
        "move_images(train_fake_folder, os.path.join(train_path, \"fake\"))\n",
        "\n",
        "# ================================\n",
        "# 4Ô∏è‚É£ SPLIT DATASET INTO TRAIN & TEST (80-20)\n",
        "# ================================\n",
        "def split_data(source_folder, train_dest, test_dest, split_ratio=0.8):\n",
        "    files = os.listdir(source_folder)\n",
        "    random.shuffle(files)\n",
        "    split_index = int(len(files) * split_ratio)\n",
        "    for f in files[split_index:]:\n",
        "        shutil.move(os.path.join(source_folder, f), os.path.join(test_dest, f))\n",
        "\n",
        "split_data(os.path.join(train_path, \"real\"), os.path.join(train_path, \"real\"), os.path.join(test_path, \"real\"))\n",
        "split_data(os.path.join(train_path, \"fake\"), os.path.join(train_path, \"fake\"), os.path.join(test_path, \"fake\"))\n",
        "\n",
        "# ================================\n",
        "# 5Ô∏è‚É£ LOAD DATASET USING PYTORCH\n",
        "# ================================\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((300, 300)),  # Reduced from 380x380 to 300x300 to save memory\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root=train_path, transform=transform)\n",
        "test_dataset = datasets.ImageFolder(root=test_path, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "# ================================\n",
        "# 6Ô∏è‚É£ DEFINE MODEL (EfficientNet-B6 + AGSK)\n",
        "# ================================\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"  # Debug mode\n",
        "torch.backends.cuda.matmul.allow_tf32 = False  # Ensure precision\n",
        "torch.cuda.set_device(0)  # Ensure the correct GPU is used\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "efficientnet_b6 = timm.create_model(\"tf_efficientnet_b6_ns\", pretrained=True)  # Fixed model name\n",
        "\n",
        "class AGSK_EfficientNetB6(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super(AGSK_EfficientNetB6, self).__init__()\n",
        "        self.feature_extractor = nn.Sequential(*list(base_model.children())[:-2])  # Adjusted feature extractor\n",
        "        self.agsk = nn.Conv2d(2304, 2304, kernel_size=3, padding=1, groups=2, bias=False)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(2304, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x.dim() != 4:\n",
        "            raise ValueError(f\"Unexpected input shape: {x.shape}\")\n",
        "\n",
        "        x = self.feature_extractor(x)\n",
        "        if x.dim() != 4:\n",
        "            raise ValueError(f\"Unexpected feature extractor output shape: {x.shape}\")\n",
        "\n",
        "        x = x.mean(dim=[2, 3])  # Safely apply GAP\n",
        "        x = self.fc(x)\n",
        "\n",
        "        if torch.isnan(x).any():\n",
        "            print(\"‚ö†Ô∏è NaN detected in model output! Skipping batch.\")\n",
        "            return torch.zeros_like(x)  # Return dummy tensor to avoid crashes\n",
        "\n",
        "        return x\n",
        "\n",
        "model = AGSK_EfficientNetB6(efficientnet_b6).to(device)\n",
        "print(f\"‚úÖ Model moved to {device}\")\n",
        "\n",
        "# ================================\n",
        "# 7Ô∏è‚É£ TRAIN THE MODEL\n",
        "# ================================\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=1e-5)\n",
        "num_epochs = 50\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct, total = 0, 0\n",
        "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.float().unsqueeze(1).to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        predictions = (outputs > 0.5).float()\n",
        "        correct += (predictions == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(train_loader):.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "torch.save(model.state_dict(), \"efficientnet_b6_agsk.pth\")\n",
        "print(\"‚úÖ Training completed and model saved!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJCMm9J2_adP",
        "outputId": "23341be9-9b5b-41d6-eb16-48dc228568d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "‚úÖ Dataset extracted successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b6_ns to current tf_efficientnet_b6.ns_jft_in1k.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model moved to cuda\n",
            "Epoch [1/50], Loss: 0.6729, Accuracy: 0.6000\n",
            "Epoch [2/50], Loss: 0.6065, Accuracy: 0.6759\n",
            "Epoch [3/50], Loss: 0.5601, Accuracy: 0.7264\n",
            "Epoch [4/50], Loss: 0.4977, Accuracy: 0.7716\n",
            "Epoch [5/50], Loss: 0.4670, Accuracy: 0.7847\n",
            "Epoch [6/50], Loss: 0.4219, Accuracy: 0.8107\n",
            "Epoch [7/50], Loss: 0.3369, Accuracy: 0.8621\n",
            "Epoch [8/50], Loss: 0.3049, Accuracy: 0.8728\n",
            "Epoch [9/50], Loss: 0.2423, Accuracy: 0.9019\n",
            "Epoch [10/50], Loss: 0.2172, Accuracy: 0.9134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"efficientnet_b6_agsk_weights.pth\")\n",
        "print(\"‚úÖ Model weights saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JoQ0TmdlTCQ",
        "outputId": "c943e785-4ad5-4644-ad74-38bd48997081"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model weights saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, \"efficientnet_b6_agsk_full.pth\")\n",
        "print(\"‚úÖ Full model saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwpPdwl9lUmI",
        "outputId": "c9f48336-26d9-4794-ad0e-98f35c67895e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Full model saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model = AGSK_EfficientNetB6(efficientnet_b6).to(device)\n",
        "\n",
        "# Load saved weights\n",
        "model.load_state_dict(torch.load(\"efficientnet_b6_agsk_weights.pth\", map_location=device))\n",
        "model.eval()  # Set to evaluation mode\n",
        "print(\"‚úÖ Model weights loaded successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYbdF0iDle5q",
        "outputId": "f91bda9d-45af-4a24-8479-31783497c740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-04b10a6ec2b2>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"efficientnet_b6_agsk_weights.pth\", map_location=device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model weights loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = {\n",
        "    \"epoch\": num_epochs,\n",
        "    \"model_state\": model.state_dict(),\n",
        "    \"optimizer_state\": optimizer.state_dict()\n",
        "}\n",
        "\n",
        "torch.save(checkpoint, \"efficientnet_b6_agsk_checkpoint.pth\")\n",
        "print(\"‚úÖ Checkpoint saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPBS3r7clyKz",
        "outputId": "ab201454-2061-48e5-c1f8-935367e4c1f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Checkpoint saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "model = AGSK_EfficientNetB6(efficientnet_b6).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=1e-5)\n",
        "\n",
        "# Load checkpoint\n",
        "checkpoint = torch.load(\"efficientnet_b6_agsk_checkpoint.pth\", map_location=device)\n",
        "model.load_state_dict(checkpoint[\"model_state\"])\n",
        "optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n",
        "\n",
        "print(f\"‚úÖ Resumed training from Epoch {checkpoint['epoch']}!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzFSFVSvmW5u",
        "outputId": "031f6946-0158-4db8-d771-1dc429989951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-ea09ca828629>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(\"efficientnet_b6_agsk_checkpoint.pth\", map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Resumed training from Epoch 50!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYtW5C0f80nX",
        "outputId": "abb8ff37-4436-4258-8a67-7c0b5da28803"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "dataset_zip = \"/content/drive/MyDrive/dataset.zip\"\n",
        "extract_path = \"/content/dataset_extracted\"\n",
        "\n",
        "# Extract dataset\n",
        "if not os.path.exists(extract_path):\n",
        "    with zipfile.ZipFile(dataset_zip, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    print(\"‚úÖ Dataset extracted successfully!\")\n",
        "else:\n",
        "    print(\"‚ö° Dataset already extracted!\")\n",
        "\n",
        "# Define paths\n",
        "train_real_folder = os.path.join(extract_path, \"training_real\")\n",
        "train_fake_folder = os.path.join(extract_path, \"training_fake\")\n",
        "\n",
        "train_path = os.path.join(extract_path, \"train\")\n",
        "test_path = os.path.join(extract_path, \"test\")\n",
        "\n",
        "# Create train/test directories\n",
        "for category in [\"real\", \"fake\"]:\n",
        "    os.makedirs(os.path.join(train_path, category), exist_ok=True)\n",
        "    os.makedirs(os.path.join(test_path, category), exist_ok=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hB46YHmXAtTq",
        "outputId": "eb97147a-479a-44ce-b3f8-91d54cba6221"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö° Dataset already extracted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_real_folder = os.path.join(extract_path, \"training_real\")\n",
        "train_fake_folder = os.path.join(extract_path, \"training_fake\")\n",
        "\n",
        "train_path = os.path.join(extract_path, \"train\")\n",
        "test_path = os.path.join(extract_path, \"test\")\n",
        "\n",
        "# Create train/test directories\n",
        "for category in [\"real\", \"fake\"]:\n",
        "    os.makedirs(os.path.join(train_path, category), exist_ok=True)\n",
        "    os.makedirs(os.path.join(test_path, category), exist_ok=True)\n"
      ],
      "metadata": {
        "id": "SgLHnGwaC55_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(source_folder, train_dest, test_dest, split_ratio=0.8):\n",
        "    files = os.listdir(source_folder)\n",
        "    random.shuffle(files)\n",
        "    split_index = int(len(files) * split_ratio)\n",
        "\n",
        "    for f in files[:split_index]:  # Move training data\n",
        "        shutil.move(os.path.join(source_folder, f), os.path.join(train_dest, f))\n",
        "\n",
        "    for f in files[split_index:]:  # Move testing data\n",
        "        shutil.move(os.path.join(source_folder, f), os.path.join(test_dest, f))\n",
        "\n",
        "split_data(train_real_folder, os.path.join(train_path, \"real\"), os.path.join(test_path, \"real\"))\n",
        "split_data(train_fake_folder, os.path.join(train_path, \"fake\"), os.path.join(test_path, \"fake\"))\n",
        "\n",
        "print(\"‚úÖ Dataset split into training and testing sets!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLgOZHurD5Sv",
        "outputId": "e339815e-8a84-409a-c322-b81071ba67de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Dataset split into training and testing sets!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load trained weights\n",
        "checkpoint = torch.load(\"/content/drive/MyDrive/efficientnet_b6_agsk_weights.pth\", map_location=device)\n",
        "if isinstance(checkpoint, dict):\n",
        "    model.load_state_dict(checkpoint)  # Load weights properly\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è The checkpoint file contains an entire model, not just state_dict.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3oVIn98EGFX",
        "outputId": "b70e7573-5213-43ce-eacb-259f51f9d4e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-4f42b5807c58>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(\"/content/drive/MyDrive/efficientnet_b6_agsk_weights.pth\", map_location=device)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Paths\n",
        "dataset_zip = \"/content/drive/MyDrive/dataset.zip\"\n",
        "extract_path = \"/content/dataset_extracted\"\n",
        "\n",
        "# Extract dataset if not already extracted\n",
        "if not os.path.exists(extract_path):\n",
        "    with zipfile.ZipFile(dataset_zip, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    print(\"‚úÖ Dataset extracted successfully!\")\n",
        "else:\n",
        "    print(\"‚ö° Dataset already extracted!\")\n",
        "\n",
        "# Define paths\n",
        "train_real_folder = os.path.join(extract_path, \"training_real\")\n",
        "train_fake_folder = os.path.join(extract_path, \"training_fake\")\n",
        "\n",
        "train_path = os.path.join(extract_path, \"train\")\n",
        "test_path = os.path.join(extract_path, \"test\")\n",
        "\n",
        "# Create train/test directories\n",
        "for category in [\"real\", \"fake\"]:\n",
        "    os.makedirs(os.path.join(train_path, category), exist_ok=True)\n",
        "    os.makedirs(os.path.join(test_path, category), exist_ok=True)\n",
        "\n",
        "# ‚úÖ Improved Data Splitting (Stratified & Copied)\n",
        "def split_data(source_folder, train_dest, test_dest, split_ratio=0.8):\n",
        "    files = os.listdir(source_folder)\n",
        "    random.shuffle(files)\n",
        "    split_index = int(len(files) * split_ratio)\n",
        "\n",
        "    for f in files[:split_index]:  # Copy training data\n",
        "        shutil.copy(os.path.join(source_folder, f), os.path.join(train_dest, f))\n",
        "\n",
        "    for f in files[split_index:]:  # Copy testing data\n",
        "        shutil.copy(os.path.join(source_folder, f), os.path.join(test_dest, f))\n",
        "\n",
        "split_data(train_real_folder, os.path.join(train_path, \"real\"), os.path.join(test_path, \"real\"))\n",
        "split_data(train_fake_folder, os.path.join(train_path, \"fake\"), os.path.join(test_path, \"fake\"))\n",
        "\n",
        "print(\"‚úÖ Dataset split into training and testing sets!\")\n",
        "\n",
        "# ‚úÖ Data Preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "test_dataset = datasets.ImageFolder(root=test_path, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "# ‚úÖ Model Definition\n",
        "class AGSK_EfficientNetB6(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super(AGSK_EfficientNetB6, self).__init__()\n",
        "        self.feature_extractor = nn.Sequential(*list(base_model.children())[:-2])\n",
        "        self.agsk = nn.Conv2d(2304, 2304, kernel_size=3, padding=1, groups=2, bias=False)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(2304, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_extractor(x)\n",
        "        x = x.mean(dim=[2, 3])  # Global Average Pooling\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# ‚úÖ Load Model & Weights\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "base_model = timm.create_model(\"tf_efficientnet_b6_ns\", pretrained=True, num_classes=0)\n",
        "model = AGSK_EfficientNetB6(base_model).to(device)\n",
        "\n",
        "checkpoint = torch.load(\"/content/drive/MyDrive/efficientnet_b6_agsk_weights.pth\", map_location=device)\n",
        "if isinstance(checkpoint, dict):\n",
        "    model.load_state_dict(checkpoint)\n",
        "    print(\"‚úÖ Model weights loaded successfully!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è The checkpoint file contains an entire model, not just state_dict.\")\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# ‚úÖ Model Evaluation\n",
        "def evaluate_model(model, test_loader):\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            preds = (outputs > 0.5).float().cpu().numpy().flatten()\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    print(f\"üî• Model Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "evaluate_model(model, test_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277,
          "referenced_widgets": [
            "e4c8372464e1435c842513d9d8ef4b98",
            "5cf47e262a4e47c0a8fdfcb824ba4e76",
            "c2bc07873c874558ac4c0624db7e84fe",
            "ce41db906ef44e299680d3ec0aadb87b",
            "26c8e994bf2b4637bc72ff9dbc1c4c6d",
            "158a10abe7674257858cf20a17ab7656",
            "75c5fbd778b14539857a45a74bac1564",
            "6c0d272d33534effb6afc871614c6d73",
            "a48fd8a218904e4b99575cc573fe828d",
            "a18029b881ef490baeadc9546a6d457b",
            "bf5655e64d3048bcba49e9ef2fac2ee4"
          ]
        },
        "id": "eFbRd5tyF8Md",
        "outputId": "c32a08c9-8155-4094-f4b7-511f804537ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö° Dataset already extracted!\n",
            "‚úÖ Dataset split into training and testing sets!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/173M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e4c8372464e1435c842513d9d8ef4b98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-202592f01761>:90: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(\"/content/drive/MyDrive/efficientnet_b6_agsk_weights.pth\", map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model weights loaded successfully!\n",
            "üî• Model Accuracy: 96.58%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Paths\n",
        "dataset_zip = \"/content/drive/MyDrive/dataset.zip\"\n",
        "extract_path = \"/content/dataset_extracted\"\n",
        "\n",
        "# Extract dataset if not already extracted\n",
        "if not os.path.exists(extract_path):\n",
        "    with zipfile.ZipFile(dataset_zip, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    print(\"‚úÖ Dataset extracted successfully!\")\n",
        "else:\n",
        "    print(\"‚ö° Dataset already extracted!\")\n",
        "\n",
        "# Define paths\n",
        "train_real_folder = os.path.join(extract_path, \"training_real\")\n",
        "train_fake_folder = os.path.join(extract_path, \"training_fake\")\n",
        "\n",
        "train_path = os.path.join(extract_path, \"train\")\n",
        "test_path = os.path.join(extract_path, \"test\")\n",
        "\n",
        "# Create train/test directories\n",
        "for category in [\"real\", \"fake\"]:\n",
        "    os.makedirs(os.path.join(train_path, category), exist_ok=True)\n",
        "    os.makedirs(os.path.join(test_path, category), exist_ok=True)\n",
        "\n",
        "# ‚úÖ Improved Data Splitting (Stratified & Copied)\n",
        "def split_data(source_folder, train_dest, test_dest, split_ratio=0.8):\n",
        "    files = os.listdir(source_folder)\n",
        "    random.shuffle(files)\n",
        "    split_index = int(len(files) * split_ratio)\n",
        "\n",
        "    for f in files[:split_index]:  # Copy training data\n",
        "        shutil.copy(os.path.join(source_folder, f), os.path.join(train_dest, f))\n",
        "\n",
        "    for f in files[split_index:]:  # Copy testing data\n",
        "        shutil.copy(os.path.join(source_folder, f), os.path.join(test_dest, f))\n",
        "\n",
        "split_data(train_real_folder, os.path.join(train_path, \"real\"), os.path.join(test_path, \"real\"))\n",
        "split_data(train_fake_folder, os.path.join(train_path, \"fake\"), os.path.join(test_path, \"fake\"))\n",
        "\n",
        "print(\"‚úÖ Dataset split into training and testing sets!\")\n",
        "\n",
        "# ‚úÖ Data Preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "test_dataset = datasets.ImageFolder(root=test_path, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "# ‚úÖ Model Definition\n",
        "class AGSK_EfficientNetB6(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super(AGSK_EfficientNetB6, self).__init__()\n",
        "        self.feature_extractor = nn.Sequential(*list(base_model.children())[:-2])\n",
        "        self.agsk = nn.Conv2d(2304, 2304, kernel_size=3, padding=1, groups=2, bias=False)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(2304, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_extractor(x)\n",
        "        x = x.mean(dim=[2, 3])  # Global Average Pooling\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# ‚úÖ Load Model & Weights\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "base_model = timm.create_model(\"tf_efficientnet_b6_ns\", pretrained=True, num_classes=0)\n",
        "model = AGSK_EfficientNetB6(base_model).to(device)\n",
        "\n",
        "checkpoint = torch.load(\"/content/drive/MyDrive/efficientnet_b6_agsk_weights.pth\", map_location=device)\n",
        "if isinstance(checkpoint, dict):\n",
        "    model.load_state_dict(checkpoint)\n",
        "    print(\"‚úÖ Model weights loaded successfully!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è The checkpoint file contains an entire model, not just state_dict.\")\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# ‚úÖ Model Evaluation (with Accuracy, Precision, Recall, and F1)\n",
        "def evaluate_model(model, test_loader):\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            preds = (outputs > 0.5).float().cpu().numpy().flatten()\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    precision = precision_score(all_labels, all_preds, average=\"binary\")\n",
        "    recall = recall_score(all_labels, all_preds, average=\"binary\")\n",
        "    f1 = f1_score(all_labels, all_preds, average=\"binary\")\n",
        "\n",
        "    print(f\"üî• Testing Accuracy: {accuracy * 100:.2f}%\")\n",
        "    print(f\"üéØ Precision: {precision:.4f}\")\n",
        "    print(f\"üìå Recall: {recall:.4f}\")\n",
        "    print(f\"‚ö° F1-Score: {f1:.4f}\")\n",
        "\n",
        "evaluate_model(model, test_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXYiExw9HPeW",
        "outputId": "c9b21004-2f82-42be-f175-6577c4da5851"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö° Dataset already extracted!\n",
            "‚úÖ Dataset split into training and testing sets!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/timm/models/_factory.py:126: UserWarning: Mapping deprecated model name tf_efficientnet_b6_ns to current tf_efficientnet_b6.ns_jft_in1k.\n",
            "  model = create_fn(\n",
            "<ipython-input-21-edc1436b14d4>:90: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(\"/content/drive/MyDrive/efficientnet_b6_agsk_weights.pth\", map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model weights loaded successfully!\n",
            "üî• Testing Accuracy: 95.84%\n",
            "üéØ Precision: 0.9673\n",
            "üìå Recall: 0.9539\n",
            "‚ö° F1-Score: 0.9606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_real_count = len(os.listdir(os.path.join(test_path, \"real\")))\n",
        "test_fake_count = len(os.listdir(os.path.join(test_path, \"fake\")))\n",
        "\n",
        "total_test_images = test_real_count + test_fake_count\n",
        "print(f\"üìä Total Testing Images: {total_test_images} (Real: {test_real_count}, Fake: {test_fake_count})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfWBOvSMIA6j",
        "outputId": "4a6d70fc-16c0-4063-8930-47171a0b0cc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Total Testing Images: 409 (Real: 217, Fake: 192)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gMRGv_G5JCwu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}